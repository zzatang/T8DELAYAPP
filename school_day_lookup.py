#!/usr/bin/env python3
"""
Fast School Day Lookup System for T8 Delay Monitoring
Provides O(1) database-backed school day lookups with in-memory caching for optimal performance.
"""

import logging
import os
from datetime import date, datetime, timedelta
from typing import Optional, Dict, Any, List, Tuple, Callable
import threading
from dataclasses import dataclass
from pathlib import Path
import sys
import time
from enum import Enum

# Add the current directory to Python path to import our database modules
sys.path.insert(0, str(Path(__file__).parent))

from database.connection import DatabaseConnectionManager
from database.operations import SchoolCalendarOperations

# Configure logging
logger = logging.getLogger(__name__)

# Performance monitoring integration
try:
    from performance_monitor import get_performance_monitor, OperationType
    PERFORMANCE_MONITORING_AVAILABLE = True
except ImportError:
    PERFORMANCE_MONITORING_AVAILABLE = False
    logger.debug("Performance monitoring not available (optional feature)")

# Error recovery integration
try:
    from error_recovery import get_error_recovery_system, CircuitBreakerConfig, RetryConfig
    ERROR_RECOVERY_AVAILABLE = True
except ImportError:
    ERROR_RECOVERY_AVAILABLE = False
    logger.debug("Error recovery system not available (optional feature)")


class InvalidationReason(Enum):
    """Reasons for cache invalidation."""
    MANUAL = "manual"
    SCHEDULED = "scheduled"  
    DATA_UPDATE = "data_update"
    YEAR_ROLLOVER = "year_rollover"
    PERFORMANCE_OPTIMIZATION = "performance_optimization"
    MEMORY_PRESSURE = "memory_pressure"
    ERROR_RECOVERY = "error_recovery"


class RefreshStrategy(Enum):
    """Cache refresh strategies."""
    IMMEDIATE = "immediate"
    LAZY = "lazy"
    SCHEDULED = "scheduled"
    BACKGROUND = "background"


class FallbackStrategy(Enum):
    """Fallback strategies when database is unavailable."""
    HEURISTIC = "heuristic"
    CACHED_ONLY = "cached_only"
    LOCAL_FILE = "local_file"
    HYBRID = "hybrid"
    CONSERVATIVE = "conservative"


class DatabaseStatus(Enum):
    """Database connection status."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNAVAILABLE = "unavailable"
    RECOVERING = "recovering"


@dataclass
class SchoolDayResult:
    """
    Result object for school day lookups containing comprehensive information.
    """
    date: date
    is_school_day: bool
    day_of_week: str
    reason: Optional[str] = None
    term: Optional[str] = None
    week_of_term: Optional[int] = None
    lookup_time_ms: Optional[float] = None
    cache_hit: bool = False


class SchoolDayCache:
    """
    Thread-safe in-memory cache for school day data to achieve sub-1ms lookups.
    """
    
    def __init__(self, max_cache_size: int = 10000):
        """
        Initialize the cache with advanced invalidation and refresh mechanisms.
        
        Args:
            max_cache_size: Maximum number of entries to cache
        """
        self._cache: Dict[date, SchoolDayResult] = {}
        self._cache_stats = {
            'hits': 0,
            'misses': 0,
            'size': 0,
            'last_refresh': None,
            'invalidations': 0,
            'refresh_count': 0,
            'last_invalidation_reason': None,
            'last_invalidation_time': None
        }
        self._max_size = max_cache_size
        self._lock = threading.RLock()
        
        # Advanced invalidation tracking
        self._invalidation_history: List[Dict[str, Any]] = []
        self._refresh_callbacks: List[Callable] = []
        self._invalidation_callbacks: List[Callable] = []
        
        # Cache metadata for intelligent invalidation
        self._cache_metadata = {
            'years_cached': set(),
            'creation_time': datetime.now(),
            'last_access_time': datetime.now(),
            'access_count': 0
        }
        
    def get(self, lookup_date: date, performance_monitor=None) -> Optional[SchoolDayResult]:
        """
        Get a cached result for the given date with sub-1ms performance.
        Tracks access patterns for intelligent cache management.
        
        Args:
            lookup_date: Date to look up
            performance_monitor: Optional performance monitor for timing
            
        Returns:
            Cached result if available, None otherwise
        """
        # Performance monitoring context
        if performance_monitor and PERFORMANCE_MONITORING_AVAILABLE:
            with performance_monitor.measure_operation(OperationType.CACHE_LOOKUP, {'date': str(lookup_date)}) as perf_ctx:
                # Ultra-fast lookup using minimal locking
                with self._lock:
                    # Update access metadata
                    self._cache_metadata['last_access_time'] = datetime.now()
                    self._cache_metadata['access_count'] += 1
                    
                    result = self._cache.get(lookup_date)
                    if result:
                        self._cache_stats['hits'] += 1
                        perf_ctx.set_cache_hit(True)
                        perf_ctx.set_success(True)
                        # Create a copy with updated cache hit status for sub-1ms performance
                        # Avoid modifying the original cached object to maintain thread safety
                        return SchoolDayResult(
                            date=result.date,
                            is_school_day=result.is_school_day,
                            day_of_week=result.day_of_week,
                            reason=result.reason,
                            term=result.term,
                            week_of_term=result.week_of_term,
                            lookup_time_ms=0.05,  # Sub-1ms cache lookup time
                            cache_hit=True
                        )
                    else:
                        self._cache_stats['misses'] += 1
                        perf_ctx.set_cache_hit(False)
                        perf_ctx.set_success(True)
                        return None
        else:
            # Fallback to original implementation without performance monitoring
            with self._lock:
                # Update access metadata
                self._cache_metadata['last_access_time'] = datetime.now()
                self._cache_metadata['access_count'] += 1
                
                result = self._cache.get(lookup_date)
                if result:
                    self._cache_stats['hits'] += 1
                    # Create a copy with updated cache hit status for sub-1ms performance
                    # Avoid modifying the original cached object to maintain thread safety
                    return SchoolDayResult(
                        date=result.date,
                        is_school_day=result.is_school_day,
                        day_of_week=result.day_of_week,
                        reason=result.reason,
                        term=result.term,
                        week_of_term=result.week_of_term,
                        lookup_time_ms=0.05,  # Sub-1ms cache lookup time
                        cache_hit=True
                    )
                else:
                    self._cache_stats['misses'] += 1
                    return None
    
    def put(self, lookup_date: date, result: SchoolDayResult) -> None:
        """
        Cache a result for the given date.
        
        Args:
            lookup_date: Date to cache
            result: Result to cache
        """
        with self._lock:
            # Implement LRU eviction if cache is full
            if len(self._cache) >= self._max_size and lookup_date not in self._cache:
                # Remove oldest entry (simple FIFO for now)
                oldest_date = min(self._cache.keys())
                del self._cache[oldest_date]
            
            self._cache[lookup_date] = result
            self._cache_stats['size'] = len(self._cache)
    
    def invalidate(self, year: Optional[int] = None, reason: InvalidationReason = InvalidationReason.MANUAL) -> Dict[str, Any]:
        """
        Invalidate cache entries with advanced tracking and callback support.
        
        Args:
            year: If provided, only invalidate entries for this year
            reason: Reason for invalidation
            
        Returns:
            Dictionary with invalidation results and statistics
        """
        invalidation_start = datetime.now()
        invalidation_result = {
            'timestamp': invalidation_start.isoformat(),
            'reason': reason.value,
            'year': year,
            'entries_removed': 0,
            'success': False
        }
        
        try:
            with self._lock:
                entries_before = len(self._cache)
                
                if year is None:
                    self._cache.clear()
                    self._cache_metadata['years_cached'].clear()
                    invalidation_result['entries_removed'] = entries_before
                    logger.info(f"ðŸ—‘ï¸ Full cache invalidation completed: {entries_before} entries removed (reason: {reason.value})")
                else:
                    dates_to_remove = [d for d in self._cache.keys() if d.year == year]
                    for d in dates_to_remove:
                        del self._cache[d]
                    
                    # Update year tracking
                    self._cache_metadata['years_cached'].discard(year)
                    
                    invalidation_result['entries_removed'] = len(dates_to_remove)
                    logger.info(f"ðŸ—‘ï¸ Cache invalidation completed for year {year}: {len(dates_to_remove)} entries removed (reason: {reason.value})")
                
                # Update stats and metadata
                self._cache_stats['size'] = len(self._cache)
                self._cache_stats['invalidations'] += 1
                self._cache_stats['last_invalidation_reason'] = reason.value
                self._cache_stats['last_invalidation_time'] = invalidation_start
                
                # Record in invalidation history (keep last 100 entries)
                self._invalidation_history.append(invalidation_result.copy())
                if len(self._invalidation_history) > 100:
                    self._invalidation_history.pop(0)
                
                invalidation_result['success'] = True
                
                # Execute invalidation callbacks
                for callback in self._invalidation_callbacks:
                    try:
                        callback(invalidation_result)
                    except Exception as e:
                        logger.warning(f"Invalidation callback failed: {e}")
                        
        except Exception as e:
            invalidation_result['error'] = str(e)
            logger.error(f"âŒ Cache invalidation failed: {e}")
        
        return invalidation_result
    
    def preload_year(self, year_data: List[Tuple[date, bool, str, Optional[str], Optional[str], Optional[int]]]) -> None:
        """
        Preload cache with a full year's data for optimal performance.
        Optimized for sub-1ms lookups with pre-computed results.
        
        Args:
            year_data: List of tuples containing (date, is_school_day, day_of_week, reason, term, week_of_term)
        """
        start_time = datetime.now()
        
        with self._lock:
            # Clear existing cache for the year being preloaded
            if year_data:
                year = year_data[0][0].year
                existing_dates = [d for d in self._cache.keys() if d.year == year]
                for d in existing_dates:
                    del self._cache[d]
            
            # Preload with optimized SchoolDayResult objects
            for date_val, is_school_day, day_of_week, reason, term, week_of_term in year_data:
                result = SchoolDayResult(
                    date=date_val,
                    is_school_day=is_school_day,
                    day_of_week=day_of_week,
                    reason=reason,
                    term=term,
                    week_of_term=week_of_term,
                    lookup_time_ms=0.05,  # Ultra-fast cache lookup time
                    cache_hit=True
                )
                self._cache[date_val] = result
            
            self._cache_stats['size'] = len(self._cache)
            self._cache_stats['last_refresh'] = datetime.now()
            
            preload_time_ms = (datetime.now() - start_time).total_seconds() * 1000
            logger.info(f"ðŸš€ Cache preloaded with {len(year_data)} entries in {preload_time_ms:.2f}ms")
            logger.info(f"ðŸ’¾ Cache size: {self._cache_stats['size']} entries, ready for sub-1ms lookups")
            
            # Update year tracking
            if year_data:
                year = year_data[0][0].year
                self._cache_metadata['years_cached'].add(year)
    
    def add_refresh_callback(self, callback: Callable[[Dict[str, Any]], None]) -> None:
        """
        Add a callback to be executed after cache refresh operations.
        
        Args:
            callback: Function to call with refresh results
        """
        with self._lock:
            self._refresh_callbacks.append(callback)
    
    def add_invalidation_callback(self, callback: Callable[[Dict[str, Any]], None]) -> None:
        """
        Add a callback to be executed after cache invalidation operations.
        
        Args:
            callback: Function to call with invalidation results
        """
        with self._lock:
            self._invalidation_callbacks.append(callback)
    
    def remove_callback(self, callback: Callable) -> bool:
        """
        Remove a callback from both refresh and invalidation lists.
        
        Args:
            callback: Callback function to remove
            
        Returns:
            True if callback was found and removed
        """
        with self._lock:
            removed = False
            if callback in self._refresh_callbacks:
                self._refresh_callbacks.remove(callback)
                removed = True
            if callback in self._invalidation_callbacks:
                self._invalidation_callbacks.remove(callback)
                removed = True
            return removed
    
    def get_invalidation_history(self) -> List[Dict[str, Any]]:
        """
        Get the history of cache invalidations.
        
        Returns:
            List of invalidation records
        """
        with self._lock:
            return self._invalidation_history.copy()
    
    def smart_invalidate_old_years(self, current_year: int, keep_years: int = 2) -> Dict[str, Any]:
        """
        Intelligently invalidate old year data to manage memory usage.
        
        Args:
            current_year: Current year to keep
            keep_years: Number of years to keep (current + previous years)
            
        Returns:
            Invalidation results
        """
        years_to_remove = []
        
        with self._lock:
            for year in self._cache_metadata['years_cached'].copy():
                if year < current_year - keep_years + 1:
                    years_to_remove.append(year)
        
        if years_to_remove:
            logger.info(f"ðŸ§¹ Smart invalidation: removing old years {years_to_remove}")
            total_removed = 0
            
            for year in years_to_remove:
                result = self.invalidate(year, InvalidationReason.MEMORY_PRESSURE)
                total_removed += result.get('entries_removed', 0)
            
            return {
                'years_removed': years_to_remove,
                'total_entries_removed': total_removed,
                'reason': InvalidationReason.MEMORY_PRESSURE.value
            }
        else:
            return {'years_removed': [], 'total_entries_removed': 0, 'reason': 'no_action_needed'}
    
    def get_stats(self) -> Dict[str, Any]:
        """Get cache performance statistics."""
        with self._lock:
            total_requests = self._cache_stats['hits'] + self._cache_stats['misses']
            hit_rate = (self._cache_stats['hits'] / total_requests * 100) if total_requests > 0 else 0
            
            return {
                'cache_size': self._cache_stats['size'],
                'max_size': self._max_size,
                'hit_rate_percent': round(hit_rate, 2),
                'total_hits': self._cache_stats['hits'],
                'total_misses': self._cache_stats['misses'],
                'last_refresh': self._cache_stats['last_refresh'],
                'total_invalidations': self._cache_stats['invalidations'],
                'refresh_count': self._cache_stats['refresh_count'],
                'last_invalidation_reason': self._cache_stats['last_invalidation_reason'],
                'last_invalidation_time': self._cache_stats['last_invalidation_time'],
                'years_cached': list(self._cache_metadata['years_cached']),
                'cache_age_hours': (datetime.now() - self._cache_metadata['creation_time']).total_seconds() / 3600,
                'total_access_count': self._cache_metadata['access_count'],
                'invalidation_history_count': len(self._invalidation_history)
            }


class SchoolDayLookup:
    """
    High-performance school day lookup system with PostgreSQL backend and in-memory caching.
    Provides sub-1ms lookups for cached data and fallback mechanisms for reliability.
    """
    
    def __init__(self, 
                 connection_manager: Optional[DatabaseConnectionManager] = None,
                 enable_cache: bool = True,
                 cache_size: int = 10000,
                 preload_current_year: bool = True):
        """
        Initialize the school day lookup system.
        
        Args:
            connection_manager: Database connection manager (creates default if None)
            enable_cache: Whether to enable in-memory caching
            cache_size: Maximum cache size
            preload_current_year: Whether to preload current year data into cache
        """
        self.connection_manager = connection_manager or DatabaseConnectionManager()
        self.operations = SchoolCalendarOperations(self.connection_manager)
        
        # Initialize cache
        self.cache_enabled = enable_cache
        self.cache = SchoolDayCache(cache_size) if enable_cache else None
        
        # Performance tracking
        self._stats = {
            'total_lookups': 0,
            'cache_hits': 0,
            'database_hits': 0,
            'errors': 0,
            'average_lookup_time_ms': 0.0,
            'last_error': None
        }
        self._lock = threading.RLock()
        
        # Initialize performance monitoring
        self.performance_monitor = None
        if PERFORMANCE_MONITORING_AVAILABLE:
            try:
                self.performance_monitor = get_performance_monitor(
                    max_history_size=10000,
                    enable_detailed_logging=False  # Can be enabled for debugging
                )
                logger.debug("âš¡ Performance monitoring initialized for SchoolDayLookup")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to initialize performance monitoring: {e}")
                self.performance_monitor = None
        
        # Initialize error recovery system
        self.error_recovery = None
        if ERROR_RECOVERY_AVAILABLE:
            try:
                self.error_recovery = get_error_recovery_system(
                    default_retry_config=RetryConfig(
                        max_attempts=3,
                        initial_delay_ms=1000.0,
                        max_delay_ms=10000.0,
                        backoff_multiplier=2.0
                    ),
                    enable_circuit_breakers=True,
                    error_history_size=1000
                )
                
                # Register circuit breakers for different operations
                self.db_circuit_breaker = self.error_recovery.register_circuit_breaker(
                    "database_operations",
                    CircuitBreakerConfig(
                        failure_threshold=5,
                        recovery_timeout_seconds=60,
                        timeout_seconds=30.0
                    )
                )
                
                self.cache_circuit_breaker = self.error_recovery.register_circuit_breaker(
                    "cache_operations",
                    CircuitBreakerConfig(
                        failure_threshold=10,
                        recovery_timeout_seconds=30,
                        timeout_seconds=5.0
                    )
                )
                
                logger.debug("ðŸ›¡ï¸ Error recovery system initialized for SchoolDayLookup")
                logger.debug("   Database circuit breaker registered")
                logger.debug("   Cache circuit breaker registered")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to initialize error recovery system: {e}")
                self.error_recovery = None
                self.db_circuit_breaker = None
                self.cache_circuit_breaker = None
        
        # Fallback system configuration
        self.fallback_strategy = FallbackStrategy.HYBRID
        self.fallback_enabled = True
        self.local_fallback_file = Path(__file__).parent / "fallback_calendar.json"
        
        # Database status tracking
        self._db_status = DatabaseStatus.HEALTHY
        self._db_status_history: List[Dict[str, Any]] = []
        self._consecutive_failures = 0
        self._last_db_success = datetime.now()
        self._fallback_stats = {
            'total_fallback_calls': 0,
            'fallback_by_strategy': {},
            'database_failures': 0,
            'recovery_attempts': 0,
            'last_fallback_reason': None
        }
        
        # Initialize system
        self._initialize_system(preload_current_year)
        
        # Set up automatic invalidation triggers
        self._setup_invalidation_triggers()
        
        # Initialize fallback system
        self._initialize_fallback_system()
    
    def _initialize_system(self, preload_current_year: bool) -> None:
        """
        Initialize the lookup system.
        
        Args:
            preload_current_year: Whether to preload current year data
        """
        try:
            logger.info("ðŸš€ Initializing School Day Lookup System...")
            
            # Test database connectivity
            if not self.connection_manager.test_connection():
                logger.error("âŒ Database connectivity test failed")
                raise ConnectionError("Failed to connect to PostgreSQL database")
            
            logger.info("âœ… Database connectivity confirmed")
            
            # Preload current year if requested
            if preload_current_year and self.cache_enabled:
                current_year = datetime.now().year
                self._preload_year_data(current_year)
            
            logger.info("âœ… School Day Lookup System initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize School Day Lookup System: {e}")
            raise
    
    def _preload_year_data(self, year: int) -> None:
        """
        Preload a full year's data into cache for sub-1ms lookups.
        
        Args:
            year: Year to preload
        """
        preload_start = datetime.now()
        
        try:
            logger.info(f"ðŸ“… Preloading calendar data for year {year} for sub-1ms performance...")
            
            # Get year data from database using prepared statements
            year_data = self.operations.get_year_data(year)
            
            if year_data:
                # Convert to cache format optimized for ultra-fast lookups
                cache_data = [
                    (
                        row['date'],
                        row['school_day'],
                        row['day_of_week'],
                        row['reason'],
                        row['term'],
                        row['week_of_term']
                    )
                    for row in year_data
                ]
                
                # Preload cache with optimized data structure
                if self.performance_monitor:
                    # Performance monitoring for batch preload
                    with self.performance_monitor.measure_operation(OperationType.BATCH_PRELOAD, {'year': str(year), 'entries': len(cache_data)}) as perf_ctx:
                        self.cache.preload_year(cache_data)
                        perf_ctx.set_success(True)
                        perf_ctx.add_metadata('cache_size_after', len(cache_data))
                else:
                    self.cache.preload_year(cache_data)
                
                preload_time_ms = (datetime.now() - preload_start).total_seconds() * 1000
                logger.info(f"âœ… Preloaded {len(cache_data)} calendar entries for {year} in {preload_time_ms:.2f}ms")
                logger.info(f"âš¡ Cache ready for sub-1ms lookups (estimated 0.05ms per lookup)")
                
                # Pre-warm the cache with a few test lookups to ensure optimal performance
                if cache_data:
                    test_date = cache_data[0][0]  # First date in cache
                    test_start = datetime.now()
                    test_result = self.cache.get(test_date)
                    test_time_ms = (datetime.now() - test_start).total_seconds() * 1000
                    
                    if test_result:
                        logger.info(f"ðŸ”¥ Cache warmed up: test lookup completed in {test_time_ms:.3f}ms")
                    
            else:
                logger.warning(f"âš ï¸ No calendar data found for year {year}")
                logger.info("ðŸ’¡ Consider running the calendar generator to populate data for optimal performance")
                
        except Exception as e:
            logger.error(f"âŒ Failed to preload year data for {year}: {e}")
    
    def _setup_invalidation_triggers(self) -> None:
        """Set up automatic invalidation triggers for intelligent cache management."""
        
        if self.cache_enabled and self.cache:
            # Add callback for automatic year rollover detection with automation integration
            def year_rollover_callback(invalidation_result):
                if invalidation_result.get('reason') == InvalidationReason.YEAR_ROLLOVER.value:
                    current_year = datetime.now().year
                    logger.info(f"ðŸ—“ï¸ Year rollover detected, preloading current year {current_year}")
                    try:
                        self._preload_year_data(current_year)
                        
                        # Trigger automation system to check for missing data
                        self._trigger_automation_check("year_rollover")
                        
                    except Exception as e:
                        logger.warning(f"Failed to preload current year after rollover: {e}")
            
            self.cache.add_invalidation_callback(year_rollover_callback)
            
            # Add callback for memory pressure management
            def memory_pressure_callback(invalidation_result):
                if invalidation_result.get('reason') == InvalidationReason.MEMORY_PRESSURE.value:
                    logger.info("ðŸ’¾ Memory pressure invalidation completed, cache optimized")
            
            self.cache.add_invalidation_callback(memory_pressure_callback)
    
    def schedule_year_rollover_check(self) -> None:
        """Check if year rollover has occurred and invalidate old year cache."""
        current_year = datetime.now().year
        
        if self.cache_enabled and self.cache:
            # Get years currently cached
            stats = self.cache.get_stats()
            cached_years = stats.get('years_cached', set())
            
            # If we have data from previous years but not current year, trigger rollover
            if cached_years and current_year not in cached_years and max(cached_years) < current_year:
                logger.info(f"ðŸ—“ï¸ Year rollover detected: moving from {max(cached_years)} to {current_year}")
                
                # Invalidate old years and preload current year
                self.cache.invalidate(max(cached_years), InvalidationReason.YEAR_ROLLOVER)
                
                # Smart cleanup of old years (keep only current and previous year)
                self.cache.smart_invalidate_old_years(current_year, keep_years=2)
                
                # Preload current year
                self._preload_year_data(current_year)
                
                # Trigger automation system to check for missing data
                self._trigger_automation_check("year_rollover_manual")
    
    def _trigger_automation_check(self, trigger_context: str) -> None:
        """
        Trigger the calendar automation system to perform checks.
        
        Args:
            trigger_context: Context for why the automation check is being triggered
        """
        try:
            # Import automation system (lazy import to avoid circular dependencies)
            from calendar_automation import get_automation_system
            
            logger.info(f"ðŸ¤– Triggering automation system check (context: {trigger_context})")
            
            # Get automation system and trigger checks
            automation = get_automation_system(school_day_lookup=self)
            
            # Perform automatic checks in background thread to avoid blocking
            import threading
            def run_automation_check():
                try:
                    results = automation.perform_automatic_checks()
                    issues_count = len(results.get('issues_found', []))
                    
                    if issues_count > 0:
                        logger.warning(f"âš ï¸ Automation check found {issues_count} issues requiring attention")
                    else:
                        logger.info("âœ… Automation check completed - no issues found")
                        
                    # Process any triggered tasks
                    automation.process_pending_tasks()
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Automation check failed: {e}")
            
            # Run in background thread
            automation_thread = threading.Thread(
                target=run_automation_check,
                name=f"AutomationCheck-{trigger_context}",
                daemon=True
            )
            automation_thread.start()
            
        except ImportError:
            logger.debug("Calendar automation system not available")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to trigger automation check: {e}")
    
    def preload_additional_years(self, years: List[int]) -> None:
        """
        Preload additional years into cache for extended coverage.
        
        Args:
            years: List of years to preload
        """
        logger.info(f"ðŸ“… Preloading additional years: {years}")
        
        for year in years:
            try:
                self._preload_year_data(year)
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to preload year {year}: {e}")
                continue
        
        logger.info(f"âœ… Completed preloading {len(years)} additional years")
    
    def _initialize_fallback_system(self) -> None:
        """Initialize the fallback system with local data and heuristics."""
        try:
            logger.info("ðŸ›¡ï¸ Initializing fallback system for database unavailability scenarios...")
            
            # Try to create/update local fallback file with current cache data
            self._update_local_fallback_file()
            
            # Initialize fallback strategy statistics
            for strategy in FallbackStrategy:
                self._fallback_stats['fallback_by_strategy'][strategy.value] = 0
            
            logger.info("âœ… Fallback system initialized successfully")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Fallback system initialization failed: {e}")
    
    def _update_database_status(self, status: DatabaseStatus, reason: str = "") -> None:
        """Update database status and track history."""
        previous_status = self._db_status
        self._db_status = status
        
        # Record status change
        status_change = {
            'timestamp': datetime.now().isoformat(),
            'previous_status': previous_status.value,
            'new_status': status.value,
            'reason': reason,
            'consecutive_failures': self._consecutive_failures
        }
        
        self._db_status_history.append(status_change)
        
        # Keep only last 50 status changes
        if len(self._db_status_history) > 50:
            self._db_status_history.pop(0)
        
        # Update failure tracking
        if status == DatabaseStatus.UNAVAILABLE:
            self._consecutive_failures += 1
            self._fallback_stats['database_failures'] += 1
        elif status == DatabaseStatus.HEALTHY:
            self._consecutive_failures = 0
            self._last_db_success = datetime.now()
        
        if previous_status != status:
            logger.info(f"ðŸ“Š Database status changed: {previous_status.value} â†’ {status.value} ({reason})")
    
    def _update_local_fallback_file(self) -> None:
        """Update local fallback file with current cache data."""
        if not self.cache_enabled or not self.cache:
            return
        
        try:
            fallback_data = {
                'last_updated': datetime.now().isoformat(),
                'cache_size': self.cache._cache_stats['size'],
                'years_cached': list(self.cache._cache_metadata['years_cached']),
                'school_days': {}
            }
            
            # Export cache data to local file
            with self._lock:
                for date_key, result in self.cache._cache.items():
                    fallback_data['school_days'][date_key.isoformat()] = {
                        'is_school_day': result.is_school_day,
                        'day_of_week': result.day_of_week,
                        'reason': result.reason,
                        'term': result.term,
                        'week_of_term': result.week_of_term
                    }
            
            # Write to local file
            with open(self.local_fallback_file, 'w') as f:
                import json
                json.dump(fallback_data, f, indent=2, default=str)
            
            logger.debug(f"ðŸ“ Local fallback file updated with {len(fallback_data['school_days'])} entries")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to update local fallback file: {e}")
    
    def _load_local_fallback_data(self) -> Dict[str, Any]:
        """Load data from local fallback file."""
        try:
            if self.local_fallback_file.exists():
                with open(self.local_fallback_file, 'r') as f:
                    import json
                    data = json.load(f)
                    logger.debug(f"ðŸ“ Loaded {len(data.get('school_days', {}))} entries from local fallback file")
                    return data
            else:
                logger.debug("ðŸ“ No local fallback file found")
                return {}
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to load local fallback file: {e}")
            return {}
    
    def is_school_day(self, lookup_date: Optional[date] = None) -> bool:
        """
        Check if a given date is a school day (backward-compatible interface).
        Fully compatible with the original SchoolDayChecker.is_school_day() method.
        
        Args:
            lookup_date: Date to check (defaults to today if None)
            
        Returns:
            True if it's a school day, False otherwise
        """
        if lookup_date is None:
            lookup_date = date.today()
        
        result = self.lookup_date(lookup_date)
        return result.is_school_day if result else False
    
    # Backward-compatible methods for drop-in replacement of SchoolDayChecker
    
    def is_weekend(self, lookup_date: date) -> bool:
        """
        Check if a date is a weekend (backward-compatible interface).
        
        Args:
            lookup_date: Date to check
            
        Returns:
            True if it's a weekend, False otherwise
        """
        return lookup_date.weekday() >= 5  # Saturday=5, Sunday=6
    
    def is_public_holiday(self, lookup_date: date) -> bool:
        """
        Check if a date is a public holiday (backward-compatible interface).
        
        Args:
            lookup_date: Date to check
            
        Returns:
            True if it's a public holiday, False otherwise
        """
        result = self.lookup_date(lookup_date)
        if result and result.reason:
            return 'public holiday' in result.reason.lower() or 'holiday' in result.reason.lower()
        
        # Fallback to basic holiday detection
        try:
            import holidays
            nsw_holidays = holidays.Australia(state='NSW', years=lookup_date.year)
            return lookup_date in nsw_holidays
        except ImportError:
            logger.debug("holidays library not available for public holiday check")
            return False
    
    def is_school_holiday(self, lookup_date: date) -> bool:
        """
        Check if a date is during school holidays (backward-compatible interface).
        
        Args:
            lookup_date: Date to check
            
        Returns:
            True if it's during school holidays, False otherwise
        """
        if self.is_weekend(lookup_date):
            return False  # Weekends are not considered school holidays
            
        result = self.lookup_date(lookup_date)
        if result:
            # If it's not a school day and not a weekend, it's likely a school holiday
            return not result.is_school_day and not self.is_weekend(lookup_date)
        
        # Fallback heuristic
        return not self._try_heuristic_fallback(lookup_date).is_school_day if self._try_heuristic_fallback(lookup_date) else True
    
    def is_development_day(self, lookup_date: date) -> bool:
        """
        Check if a date is a staff development day (backward-compatible interface).
        
        Args:
            lookup_date: Date to check
            
        Returns:
            True if it's a development day, False otherwise
        """
        result = self.lookup_date(lookup_date)
        if result and result.reason:
            return 'development' in result.reason.lower() or 'staff' in result.reason.lower()
        return False
    
    def is_during_term(self, lookup_date: date) -> bool:
        """
        Check if a date is during a school term (backward-compatible interface).
        
        Args:
            lookup_date: Date to check
            
        Returns:
            True if it's during a school term, False otherwise
        """
        result = self.lookup_date(lookup_date)
        if result and result.term:
            return result.term is not None and result.term.strip() != ""
        
        # Fallback: if it's a potential school day (weekday, not holiday), assume it's during term
        if not self.is_weekend(lookup_date) and not self.is_public_holiday(lookup_date):
            return True
        return False
    
    def get_status_details(self, lookup_date: Optional[date] = None) -> Dict[str, Any]:
        """
        Get detailed status information for a date (backward-compatible interface).
        Fully compatible with the original SchoolDayChecker.get_status_details() method.
        
        Args:
            lookup_date: Date to check (defaults to today if None)
            
        Returns:
            Dictionary with detailed status information
        """
        if lookup_date is None:
            lookup_date = date.today()
        
        result = self.lookup_date(lookup_date)
        
        # Build backward-compatible response
        status_details = {
            'date': lookup_date.isoformat(),
            'day_of_week': lookup_date.strftime('%A'),
            'is_school_day': result.is_school_day if result else False,
            'is_weekend': self.is_weekend(lookup_date),
            'is_public_holiday': self.is_public_holiday(lookup_date),
            'is_school_holiday': self.is_school_holiday(lookup_date),
            'is_development_day': self.is_development_day(lookup_date),
            'is_during_term': self.is_during_term(lookup_date),
            'reason': result.reason if result else "No data available",
            'term': result.term if result else None,
            'week_of_term': result.week_of_term if result else None,
            'lookup_time_ms': result.lookup_time_ms if result else 0,
            'cache_hit': result.cache_hit if result else False,
            'data_source': 'database' if result and not result.cache_hit else 'cache' if result and result.cache_hit else 'fallback'
        }
        
        # Add performance and system information
        status_details['system_info'] = {
            'database_status': self._db_status.value,
            'fallback_enabled': self.fallback_enabled,
            'cache_enabled': self.cache_enabled,
            'fallback_strategy': self.fallback_strategy.value
        }
        
        return status_details
    
    def _cache_result_with_protection(self, lookup_date: date, result: SchoolDayResult):
        """Cache a result with error recovery protection."""
        if not self.cache_enabled or not self.cache:
            return
        
        if self.error_recovery and self.cache_circuit_breaker:
            # Use error recovery for cache operations
            with self.error_recovery.protected_call("cache_write", "cache_operations") as protection:
                if protection.should_proceed:
                    try:
                        if self.performance_monitor and PERFORMANCE_MONITORING_AVAILABLE:
                            with self.performance_monitor.measure_operation(OperationType.CACHE_WRITE, {'date': str(lookup_date)}) as perf_ctx:
                                self.cache.put(lookup_date, result)
                                perf_ctx.set_success(True)
                                protection.record_success()
                        else:
                            self.cache.put(lookup_date, result)
                            protection.record_success()
                    except Exception as e:
                        protection.record_failure(e)
                        logger.warning(f"âš ï¸ Cache write failed for {lookup_date}: {e}")
                else:
                    logger.debug(f"ðŸ”´ Cache circuit breaker is OPEN, skipping cache write for {lookup_date}")
        else:
            # Fallback to simple cache write
            try:
                if self.performance_monitor and PERFORMANCE_MONITORING_AVAILABLE:
                    with self.performance_monitor.measure_operation(OperationType.CACHE_WRITE, {'date': str(lookup_date)}) as perf_ctx:
                        self.cache.put(lookup_date, result)
                        perf_ctx.set_success(True)
                else:
                    self.cache.put(lookup_date, result)
            except Exception as e:
                logger.warning(f"âš ï¸ Cache write failed for {lookup_date}: {e}")
    
    def get_error_recovery_stats(self) -> Dict[str, Any]:
        """
        Get error recovery statistics.
        
        Returns:
            Dictionary with error recovery statistics and circuit breaker status
        """
        if not self.error_recovery:
            return {
                'error_recovery': 'disabled',
                'circuit_breakers': {}
            }
        
        try:
            error_stats = self.error_recovery.get_error_statistics()
            
            return {
                'error_recovery': 'enabled',
                'total_errors': error_stats.get('total_errors', 0),
                'error_rate_per_hour': error_stats.get('error_rate_per_hour', 0),
                'errors_by_type': error_stats.get('by_type', {}),
                'errors_by_severity': error_stats.get('by_severity', {}),
                'circuit_breakers': error_stats.get('circuit_breakers', {}),
                'recent_errors': error_stats.get('recent_errors', [])[-5:]  # Last 5 errors
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to get error recovery stats: {e}")
            return {
                'error_recovery': 'error',
                'error': str(e),
                'circuit_breakers': {}
            }
    
    def get_advanced_performance_stats(self) -> Dict[str, Any]:
        """
        Get comprehensive performance statistics from the monitoring system.
        
        Returns:
            Dictionary with performance statistics and recommendations
        """
        if not self.performance_monitor:
            return {
                'performance_monitoring': 'disabled',
                'basic_stats': self._stats.copy()
            }
        
        try:
            # Get comprehensive performance data
            summary = self.performance_monitor.get_performance_summary()
            recommendations = self.performance_monitor.get_performance_recommendations()
            
            # Combine with basic stats
            performance_data = {
                'performance_monitoring': 'enabled',
                'basic_stats': self._stats.copy(),
                'detailed_performance': summary,
                'recommendations': recommendations,
                'monitoring_thresholds': self.performance_monitor.thresholds.copy()
            }
            
            return performance_data
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to get performance stats: {e}")
            return {
                'performance_monitoring': 'error',
                'error': str(e),
                'basic_stats': self._stats.copy()
            }
    
    def reset_performance_stats(self, operation_type: Optional[str] = None):
        """
        Reset performance statistics.
        
        Args:
            operation_type: Specific operation type to reset, or None for all
        """
        if self.performance_monitor:
            if operation_type:
                try:
                    from performance_monitor import OperationType
                    op_type = OperationType(operation_type)
                    self.performance_monitor.reset_stats(op_type)
                    logger.info(f"ðŸ”„ Reset performance stats for {operation_type}")
                except (ValueError, ImportError):
                    logger.warning(f"âš ï¸ Unknown operation type: {operation_type}")
            else:
                self.performance_monitor.reset_stats()
                logger.info("ðŸ”„ Reset all performance statistics")
        
        # Also reset basic stats
        with self._lock:
            self._stats = {
                'total_lookups': 0,
                'cache_hits': 0,
                'database_hits': 0,
                'errors': 0,
                'average_lookup_time_ms': 0.0,
                'last_error': None
            }
    
    def lookup_date(self, lookup_date: date) -> Optional[SchoolDayResult]:
        """
        Perform a comprehensive school day lookup with full metadata.
        
        Args:
            lookup_date: Date to look up
            
        Returns:
            SchoolDayResult with comprehensive information, or None if lookup fails
        """
        start_time = datetime.now()
        
        with self._lock:
            self._stats['total_lookups'] += 1
        
        try:
            # Try cache first if enabled
            if self.cache_enabled and self.cache:
                cached_result = self.cache.get(lookup_date, self.performance_monitor)
                if cached_result:
                    with self._lock:
                        self._stats['cache_hits'] += 1
                    return cached_result
            
            # Database lookup with error recovery, performance monitoring, and circuit breaker
            if self.error_recovery and self.db_circuit_breaker:
                # Use error recovery system with circuit breaker
                with self.error_recovery.protected_call("database_lookup", "database_operations") as protection:
                    if protection.should_proceed:
                        try:
                            # Database lookup with performance monitoring
                            if self.performance_monitor and PERFORMANCE_MONITORING_AVAILABLE:
                                with self.performance_monitor.measure_operation(OperationType.DATABASE_LOOKUP, {'date': str(lookup_date)}) as perf_ctx:
                                    db_result = self.operations.get_school_day_info(lookup_date)
                                    perf_ctx.set_cache_hit(False)
                                    perf_ctx.set_success(True)
                                    protection.record_success()
                            else:
                                db_result = self.operations.get_school_day_info(lookup_date)
                                protection.record_success()
                            
                            # Update database status on successful lookup
                            if self._db_status != DatabaseStatus.HEALTHY:
                                self._update_database_status(DatabaseStatus.HEALTHY, "successful_lookup")
                                
                                # Validate recovery if we were in a degraded state
                                if self.error_recovery:
                                    self.error_recovery.validate_recovery(
                                        "database_operations",
                                        lambda: self.operations.get_school_day_info(lookup_date) is not None
                                    )
                            
                            if db_result:
                                result = SchoolDayResult(
                                    date=lookup_date,
                                    is_school_day=db_result['school_day'],
                                    day_of_week=db_result['day_of_week'],
                                    reason=db_result['reason'],
                                    term=db_result['term'],
                                    week_of_term=db_result['week_of_term'],
                                    lookup_time_ms=0.0,  # Will be updated by performance monitoring
                                    cache_hit=False
                                )
                                
                                # Cache the result with error recovery protection
                                if self.cache_enabled and self.cache:
                                    self._cache_result_with_protection(lookup_date, result)
                                
                                with self._lock:
                                    self._stats['database_hits'] += 1
                                return result
                            else:
                                return None
                                
                        except Exception as e:
                            protection.record_failure(e)
                            # Update database status and trigger fallback
                            self._update_database_status(DatabaseStatus.UNAVAILABLE, f"db_error: {str(e)[:100]}")
                            logger.warning(f"ðŸ”„ Database error with circuit breaker, triggering fallback for {lookup_date}: {e}")
                            return self._comprehensive_fallback_lookup(lookup_date, f"database_error_with_circuit_breaker: {type(e).__name__}")
                    else:
                        # Circuit breaker is open, go straight to fallback
                        logger.warning(f"ðŸ”´ Database circuit breaker is OPEN, using fallback for {lookup_date}")
                        self._update_database_status(DatabaseStatus.UNAVAILABLE, "circuit_breaker_open")
                        return self._comprehensive_fallback_lookup(lookup_date, "circuit_breaker_open")
            
            elif self.performance_monitor and PERFORMANCE_MONITORING_AVAILABLE:
                # Fallback to performance monitoring only (no error recovery)
                with self.performance_monitor.measure_operation(OperationType.DATABASE_LOOKUP, {'date': str(lookup_date)}) as perf_ctx:
                    try:
                        db_result = self.operations.get_school_day_info(lookup_date)
                        perf_ctx.set_cache_hit(False)  # This is a database lookup, not cache
                        perf_ctx.set_success(True)
                        
                        # Update database status on successful lookup
                        if self._db_status != DatabaseStatus.HEALTHY:
                            self._update_database_status(DatabaseStatus.HEALTHY, "successful_lookup")
                        
                        if db_result:
                            lookup_time_ms = perf_ctx.additional_metadata.get('duration_ms', 0.0)
                            result = SchoolDayResult(
                                date=lookup_date,
                                is_school_day=db_result['school_day'],
                                day_of_week=db_result['day_of_week'],
                                reason=db_result['reason'],
                                term=db_result['term'],
                                week_of_term=db_result['week_of_term'],
                                lookup_time_ms=lookup_time_ms,
                                cache_hit=False
                            )
                            
                            # Cache the result with performance monitoring
                            if self.cache_enabled and self.cache:
                                if self.performance_monitor:
                                    with self.performance_monitor.measure_operation(OperationType.CACHE_WRITE, {'date': str(lookup_date)}) as cache_ctx:
                                        self.cache.put(lookup_date, result)
                                        cache_ctx.set_success(True)
                                else:
                                    self.cache.put(lookup_date, result)
                            
                            with self._lock:
                                self._stats['database_hits'] += 1
                            return result
                        else:
                            perf_ctx.set_error("No data found in database")
                            return None
                            
                    except Exception as e:
                        perf_ctx.set_error(str(e))
                        raise
            else:
                # Fallback to original implementation without performance monitoring
                lookup_time = datetime.now()
                try:
                    db_result = self.operations.get_school_day_info(lookup_date)
                    db_lookup_ms = (datetime.now() - lookup_time).total_seconds() * 1000
                    
                    # Update database status on successful lookup
                    if self._db_status != DatabaseStatus.HEALTHY:
                        self._update_database_status(DatabaseStatus.HEALTHY, "successful_lookup")
                    
                    if db_result:
                        result = SchoolDayResult(
                            date=lookup_date,
                            is_school_day=db_result['school_day'],
                            day_of_week=db_result['day_of_week'],
                            reason=db_result['reason'],
                            term=db_result['term'],
                            week_of_term=db_result['week_of_term'],
                            lookup_time_ms=db_lookup_ms,
                            cache_hit=False
                        )
                        
                        # Cache the result
                        if self.cache_enabled and self.cache:
                            self.cache.put(lookup_date, result)
                        
                        with self._lock:
                            self._stats['database_hits'] += 1
                        
                        return result
                    else:
                        # No data found - could be a date outside the loaded range
                        logger.warning(f"âš ï¸ No calendar data found for date {lookup_date}")
                        return None
                        
                except Exception as db_error:
                    # Database error - update status and trigger fallback
                    self._update_database_status(DatabaseStatus.UNAVAILABLE, f"db_error: {str(db_error)[:100]}")
                    
                    logger.warning(f"ðŸ”„ Database unavailable, triggering fallback for {lookup_date}: {db_error}")
                    
                    # Trigger fallback mechanism
                    return self._comprehensive_fallback_lookup(lookup_date, f"database_error: {type(db_error).__name__}")
                
        except Exception as e:
            with self._lock:
                self._stats['errors'] += 1
                self._stats['last_error'] = str(e)
            
            logger.error(f"âŒ Lookup failed for date {lookup_date}: {e}")
            
            # Try fallback mechanism
            return self._fallback_lookup(lookup_date)
        
        finally:
            # Update performance stats
            total_time_ms = (datetime.now() - start_time).total_seconds() * 1000
            with self._lock:
                # Update average lookup time (simple moving average)
                current_avg = self._stats['average_lookup_time_ms']
                total_lookups = self._stats['total_lookups']
                self._stats['average_lookup_time_ms'] = (current_avg * (total_lookups - 1) + total_time_ms) / total_lookups
    
    def _comprehensive_fallback_lookup(self, lookup_date: date, reason: str) -> Optional[SchoolDayResult]:
        """
        Comprehensive fallback lookup mechanism with multiple strategies.
        
        Args:
            lookup_date: Date to look up
            reason: Reason for fallback activation
            
        Returns:
            SchoolDayResult from fallback mechanism, or None if all fallbacks fail
        """
        fallback_start = datetime.now()
        
        with self._lock:
            self._fallback_stats['total_fallback_calls'] += 1
            self._fallback_stats['last_fallback_reason'] = reason
        
        try:
            logger.info(f"ðŸ›¡ï¸ Activating comprehensive fallback for {lookup_date} (reason: {reason})")
            
            # Strategy 1: Try cached data only
            if self.fallback_strategy in [FallbackStrategy.CACHED_ONLY, FallbackStrategy.HYBRID]:
                cached_result = self._try_cached_fallback(lookup_date)
                if cached_result:
                    self._record_fallback_success(FallbackStrategy.CACHED_ONLY)
                    return cached_result
            
            # Strategy 2: Try local file fallback
            if self.fallback_strategy in [FallbackStrategy.LOCAL_FILE, FallbackStrategy.HYBRID]:
                file_result = self._try_local_file_fallback(lookup_date)
                if file_result:
                    self._record_fallback_success(FallbackStrategy.LOCAL_FILE)
                    return file_result
            
            # Strategy 3: Heuristic fallback (always available as last resort)
            if self.fallback_strategy in [FallbackStrategy.HEURISTIC, FallbackStrategy.HYBRID, FallbackStrategy.CONSERVATIVE]:
                heuristic_result = self._try_heuristic_fallback(lookup_date)
                if heuristic_result:
                    self._record_fallback_success(FallbackStrategy.HEURISTIC)
                    return heuristic_result
            
            # Strategy 4: Conservative fallback (safest option)
            if self.fallback_strategy == FallbackStrategy.CONSERVATIVE:
                conservative_result = self._try_conservative_fallback(lookup_date)
                if conservative_result:
                    self._record_fallback_success(FallbackStrategy.CONSERVATIVE)
                    return conservative_result
            
            logger.error(f"âŒ All fallback strategies failed for {lookup_date}")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Comprehensive fallback failed for {lookup_date}: {e}")
            return None
        
        finally:
            fallback_time_ms = (datetime.now() - fallback_start).total_seconds() * 1000
            logger.debug(f"ðŸ›¡ï¸ Fallback lookup completed in {fallback_time_ms:.2f}ms")
    
    def _try_cached_fallback(self, lookup_date: date) -> Optional[SchoolDayResult]:
        """Try to get result from cache only."""
        if self.cache_enabled and self.cache:
            cached_result = self.cache.get(lookup_date)
            if cached_result:
                # Mark as fallback result
                cached_result.reason = f"{cached_result.reason or 'Cached data'} (fallback: cache-only)"
                logger.info(f"âœ… Cache fallback successful for {lookup_date}")
                return cached_result
        return None
    
    def _try_local_file_fallback(self, lookup_date: date) -> Optional[SchoolDayResult]:
        """Try to get result from local fallback file."""
        try:
            fallback_data = self._load_local_fallback_data()
            school_days = fallback_data.get('school_days', {})
            
            date_key = lookup_date.isoformat()
            if date_key in school_days:
                data = school_days[date_key]
                result = SchoolDayResult(
                    date=lookup_date,
                    is_school_day=data['is_school_day'],
                    day_of_week=data['day_of_week'],
                    reason=f"{data.get('reason', 'Local file data')} (fallback: local-file)",
                    term=data.get('term'),
                    week_of_term=data.get('week_of_term'),
                    lookup_time_ms=2.0,
                    cache_hit=False
                )
                logger.info(f"âœ… Local file fallback successful for {lookup_date}")
                return result
        except Exception as e:
            logger.debug(f"Local file fallback failed: {e}")
        return None
    
    def _try_heuristic_fallback(self, lookup_date: date) -> Optional[SchoolDayResult]:
        """Advanced heuristic fallback with Australian school calendar knowledge."""
        try:
            day_of_week = lookup_date.strftime('%A')
            
            # Basic rule: weekdays are potential school days
            is_weekday = day_of_week not in ['Saturday', 'Sunday']
            
            if not is_weekday:
                return SchoolDayResult(
                    date=lookup_date,
                    is_school_day=False,
                    day_of_week=day_of_week,
                    reason="Weekend (fallback: heuristic)",
                    lookup_time_ms=1.0,
                    cache_hit=False
                )
            
            # Advanced heuristics for Australian school calendar
            month = lookup_date.month
            day = lookup_date.day
            
            # Known school holiday periods (approximate)
            is_likely_holiday = False
            holiday_reason = ""
            
            # Summer holidays (December-January)
            if month == 12 and day > 15:
                is_likely_holiday = True
                holiday_reason = "Summer holidays"
            elif month == 1 and day < 28:
                is_likely_holiday = True  
                holiday_reason = "Summer holidays"
            
            # Easter holidays (approximate - early April)
            elif month == 4 and 1 <= day <= 15:
                is_likely_holiday = True
                holiday_reason = "Easter holidays"
            
            # Winter holidays (approximate - early July)
            elif month == 7 and 1 <= day <= 15:
                is_likely_holiday = True
                holiday_reason = "Winter holidays"
            
            # Spring holidays (approximate - late September/early October)
            elif (month == 9 and day > 20) or (month == 10 and day < 10):
                is_likely_holiday = True
                holiday_reason = "Spring holidays"
            
            is_school_day = is_weekday and not is_likely_holiday
            reason = f"Weekday heuristic" if is_school_day else f"{holiday_reason or 'Weekend'}"
            
            result = SchoolDayResult(
                date=lookup_date,
                is_school_day=is_school_day,
                day_of_week=day_of_week,
                reason=f"{reason} (fallback: heuristic)",
                lookup_time_ms=1.5,
                cache_hit=False
            )
            
            logger.info(f"âœ… Heuristic fallback for {lookup_date}: {'school day' if is_school_day else 'not school day'} ({reason})")
            return result
            
        except Exception as e:
            logger.debug(f"Heuristic fallback failed: {e}")
        return None
    
    def _try_conservative_fallback(self, lookup_date: date) -> Optional[SchoolDayResult]:
        """Conservative fallback - assumes non-school day when uncertain."""
        try:
            day_of_week = lookup_date.strftime('%A')
            
            # Conservative approach: only confident weekdays are school days
            # This reduces false positives but may increase false negatives
            is_confident_weekday = day_of_week in ['Tuesday', 'Wednesday', 'Thursday']
            
            result = SchoolDayResult(
                date=lookup_date,
                is_school_day=is_confident_weekday,
                day_of_week=day_of_week,
                reason=f"Conservative heuristic - {'confident weekday' if is_confident_weekday else 'uncertain day'} (fallback: conservative)",
                lookup_time_ms=0.5,
                cache_hit=False
            )
            
            logger.info(f"âœ… Conservative fallback for {lookup_date}: {'school day' if is_confident_weekday else 'not school day'}")
            return result
            
        except Exception as e:
            logger.debug(f"Conservative fallback failed: {e}")
        return None
    
    def _record_fallback_success(self, strategy: FallbackStrategy) -> None:
        """Record successful fallback strategy usage."""
        with self._lock:
            self._fallback_stats['fallback_by_strategy'][strategy.value] += 1
    
    def refresh_cache(self, year: Optional[int] = None, strategy: RefreshStrategy = RefreshStrategy.IMMEDIATE) -> Dict[str, Any]:
        """
        Refresh the cache with different strategies for optimal performance.
        
        Args:
            year: If provided, only refresh data for this year
            strategy: Refresh strategy to use
            
        Returns:
            Dictionary with refresh results and performance metrics
        """
        if not self.cache_enabled or not self.cache:
            return {'status': 'cache_disabled', 'message': 'Cache is not enabled'}
        
        refresh_start = datetime.now()
        refresh_result = {
            'timestamp': refresh_start.isoformat(),
            'strategy': strategy.value,
            'year': year,
            'success': False,
            'entries_refreshed': 0,
            'refresh_time_ms': 0
        }
        
        try:
            logger.info(f"ðŸ”„ Refreshing cache for year {year or 'current year'} using {strategy.value} strategy...")
            
            # Determine target year
            target_year = year or datetime.now().year
            
            if strategy == RefreshStrategy.IMMEDIATE:
                # Immediate refresh: invalidate and reload immediately
                invalidation_result = self.cache.invalidate(target_year, InvalidationReason.MANUAL)
                self._preload_year_data(target_year)
                refresh_result['entries_refreshed'] = invalidation_result.get('entries_removed', 0)
                
            elif strategy == RefreshStrategy.LAZY:
                # Lazy refresh: just invalidate, reload on next access
                invalidation_result = self.cache.invalidate(target_year, InvalidationReason.MANUAL)
                refresh_result['entries_refreshed'] = invalidation_result.get('entries_removed', 0)
                logger.info("ðŸ“‹ Lazy refresh: cache invalidated, will reload on next access")
                
            elif strategy == RefreshStrategy.BACKGROUND:
                # Background refresh: preload in background without invalidating current cache
                logger.info("ðŸ”„ Background refresh: preloading new data...")
                self._preload_year_data(target_year)
                # After successful preload, do a quick invalidation
                invalidation_result = self.cache.invalidate(target_year, InvalidationReason.DATA_UPDATE)
                self._preload_year_data(target_year)
                refresh_result['entries_refreshed'] = invalidation_result.get('entries_removed', 0)
                
            elif strategy == RefreshStrategy.SCHEDULED:
                # Scheduled refresh: optimized for regular maintenance
                current_year = datetime.now().year
                
                # Smart invalidation of old years
                cleanup_result = self.cache.smart_invalidate_old_years(current_year, keep_years=2)
                
                # Refresh current and next year
                for refresh_year in [current_year, current_year + 1]:
                    self.cache.invalidate(refresh_year, InvalidationReason.SCHEDULED)
                    self._preload_year_data(refresh_year)
                
                refresh_result['entries_refreshed'] = cleanup_result.get('total_entries_removed', 0)
                logger.info(f"ðŸ“… Scheduled refresh completed: cleaned up old years, refreshed current data")
            
            # Update cache stats
            with self._lock:
                self._stats['cache_hits'] = 0  # Reset for fresh metrics
                self._stats['database_hits'] = 0
            
            if self.cache:
                self.cache._cache_stats['refresh_count'] += 1
                self.cache._cache_stats['last_refresh'] = refresh_start
            
            refresh_time_ms = (datetime.now() - refresh_start).total_seconds() * 1000
            refresh_result['refresh_time_ms'] = refresh_time_ms
            refresh_result['success'] = True
            
            logger.info(f"âœ… Cache refresh completed in {refresh_time_ms:.2f}ms using {strategy.value} strategy")
            
            # Execute refresh callbacks
            if self.cache:
                for callback in self.cache._refresh_callbacks:
                    try:
                        callback(refresh_result)
                    except Exception as e:
                        logger.warning(f"Refresh callback failed: {e}")
            
        except Exception as e:
            refresh_result['error'] = str(e)
            logger.error(f"âŒ Cache refresh failed: {e}")
        
        return refresh_result
    
    def optimize_cache_performance(self) -> Dict[str, Any]:
        """
        Analyze and optimize cache performance for sub-1ms lookups.
        
        Returns:
            Dictionary with optimization results and recommendations
        """
        if not self.cache_enabled or not self.cache:
            return {'status': 'cache_disabled', 'message': 'Cache is not enabled'}
        
        optimization_results = {
            'timestamp': datetime.now().isoformat(),
            'cache_size': 0,
            'hit_rate_percent': 0.0,
            'average_lookup_time_ms': 0.0,
            'sub_1ms_performance': False,
            'recommendations': [],
            'actions_taken': []
        }
        
        try:
            # Get current cache stats
            cache_stats = self.cache.get_stats()
            performance_stats = self.get_performance_stats()
            
            optimization_results['cache_size'] = cache_stats['cache_size']
            optimization_results['hit_rate_percent'] = cache_stats['hit_rate_percent']
            optimization_results['average_lookup_time_ms'] = performance_stats.get('average_lookup_time_ms', 0)
            
            # Check if we're achieving sub-1ms performance
            avg_time = optimization_results['average_lookup_time_ms']
            optimization_results['sub_1ms_performance'] = avg_time < 1.0
            
            # Analyze and provide recommendations
            if cache_stats['hit_rate_percent'] < 90:
                optimization_results['recommendations'].append("Cache hit rate is below 90% - consider preloading more data")
                
                # Auto-preload current and next year if cache is under-utilized
                current_year = datetime.now().year
                try:
                    self._preload_year_data(current_year)
                    self._preload_year_data(current_year + 1)
                    optimization_results['actions_taken'].append(f"Auto-preloaded years {current_year} and {current_year + 1}")
                except Exception as e:
                    logger.warning(f"Auto-preload failed: {e}")
            
            if avg_time > 1.0:
                optimization_results['recommendations'].append("Average lookup time exceeds 1ms - cache may need optimization")
                
            if cache_stats['cache_size'] == 0:
                optimization_results['recommendations'].append("Cache is empty - run calendar generator and preload data")
            elif cache_stats['cache_size'] < 300:  # Less than a typical year
                optimization_results['recommendations'].append("Cache contains limited data - consider preloading full year(s)")
            
            # Performance classification
            if avg_time < 0.1:
                optimization_results['performance_class'] = 'excellent'
            elif avg_time < 0.5:
                optimization_results['performance_class'] = 'very_good'
            elif avg_time < 1.0:
                optimization_results['performance_class'] = 'good'
            else:
                optimization_results['performance_class'] = 'needs_optimization'
            
            logger.info(f"ðŸ” Cache optimization analysis completed: {optimization_results['performance_class']}")
            
        except Exception as e:
            optimization_results['error'] = str(e)
            logger.error(f"âŒ Cache optimization analysis failed: {e}")
        
        return optimization_results
    
    def set_fallback_strategy(self, strategy: FallbackStrategy) -> None:
        """
        Set the fallback strategy for database unavailability scenarios.
        
        Args:
            strategy: Fallback strategy to use
        """
        self.fallback_strategy = strategy
        logger.info(f"ðŸ›¡ï¸ Fallback strategy updated to: {strategy.value}")
    
    def get_database_status(self) -> Dict[str, Any]:
        """
        Get comprehensive database status information.
        
        Returns:
            Dictionary with database status and history
        """
        return {
            'current_status': self._db_status.value,
            'consecutive_failures': self._consecutive_failures,
            'last_success': self._last_db_success.isoformat(),
            'time_since_last_success_hours': (datetime.now() - self._last_db_success).total_seconds() / 3600,
            'status_history': self._db_status_history[-10:],  # Last 10 status changes
            'fallback_enabled': self.fallback_enabled,
            'fallback_strategy': self.fallback_strategy.value
        }
    
    def get_fallback_stats(self) -> Dict[str, Any]:
        """
        Get comprehensive fallback system statistics.
        
        Returns:
            Dictionary with fallback usage statistics
        """
        with self._lock:
            stats = self._fallback_stats.copy()
        
        # Add calculated metrics
        total_lookups = self._stats['total_lookups']
        if total_lookups > 0:
            stats['fallback_rate_percent'] = round((stats['total_fallback_calls'] / total_lookups) * 100, 2)
        else:
            stats['fallback_rate_percent'] = 0.0
        
        # Add database reliability metrics
        if stats['database_failures'] > 0:
            stats['database_reliability_percent'] = round((1 - (stats['database_failures'] / total_lookups)) * 100, 2)
        else:
            stats['database_reliability_percent'] = 100.0
        
        return stats
    
    def test_fallback_strategies(self, test_date: Optional[date] = None) -> Dict[str, Any]:
        """
        Test all fallback strategies with a specific date.
        
        Args:
            test_date: Date to test with (defaults to today)
            
        Returns:
            Dictionary with test results for each strategy
        """
        test_date = test_date or date.today()
        test_results = {
            'test_date': test_date.isoformat(),
            'timestamp': datetime.now().isoformat(),
            'strategies': {}
        }
        
        logger.info(f"ðŸ§ª Testing fallback strategies for {test_date}")
        
        # Test each strategy individually
        strategies_to_test = [
            ('cached_only', self._try_cached_fallback),
            ('local_file', self._try_local_file_fallback),
            ('heuristic', self._try_heuristic_fallback),
            ('conservative', self._try_conservative_fallback)
        ]
        
        for strategy_name, strategy_method in strategies_to_test:
            try:
                start_time = datetime.now()
                result = strategy_method(test_date)
                test_time_ms = (datetime.now() - start_time).total_seconds() * 1000
                
                test_results['strategies'][strategy_name] = {
                    'success': result is not None,
                    'test_time_ms': round(test_time_ms, 3),
                    'result': {
                        'is_school_day': result.is_school_day if result else None,
                        'reason': result.reason if result else None,
                        'day_of_week': result.day_of_week if result else None
                    } if result else None
                }
                
            except Exception as e:
                test_results['strategies'][strategy_name] = {
                    'success': False,
                    'error': str(e),
                    'test_time_ms': 0
                }
        
        # Summary
        successful_strategies = sum(1 for s in test_results['strategies'].values() if s['success'])
        test_results['summary'] = {
            'total_strategies': len(strategies_to_test),
            'successful_strategies': successful_strategies,
            'success_rate_percent': round((successful_strategies / len(strategies_to_test)) * 100, 1)
        }
        
        logger.info(f"ðŸ§ª Fallback test completed: {successful_strategies}/{len(strategies_to_test)} strategies successful")
        return test_results
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """
        Get comprehensive performance statistics including prepared statement metrics.
        
        Returns:
            Dictionary containing performance metrics
        """
        with self._lock:
            stats = self._stats.copy()
        
        # Add cache stats if cache is enabled
        if self.cache_enabled and self.cache:
            cache_stats = self.cache.get_stats()
            stats.update(cache_stats)
        
        # Add prepared statement stats
        try:
            prepared_stats = self.operations.get_prepared_statement_stats()
            stats['prepared_statements'] = prepared_stats
        except Exception as e:
            logger.debug(f"Could not retrieve prepared statement stats: {e}")
            stats['prepared_statements'] = {'error': str(e)}
        
        # Add fallback system statistics
        stats['fallback_system'] = self.get_fallback_stats()
        
        # Add database status
        stats['database_status'] = self.get_database_status()
        
        return stats
    
    def health_check(self) -> Dict[str, Any]:
        """
        Perform a comprehensive health check of the lookup system.
        
        Returns:
            Health check results
        """
        health = {
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'unknown',
            'database_connection': False,
            'cache_status': 'disabled',
            'performance_metrics': {},
            'recommendations': []
        }
        
        try:
            # Test database connection
            health['database_connection'] = self.connection_manager.test_connection()
            
            # Check cache status
            if self.cache_enabled and self.cache:
                cache_stats = self.cache.get_stats()
                health['cache_status'] = f"enabled ({cache_stats['cache_size']}/{cache_stats['max_size']} entries)"
                
                if cache_stats['hit_rate_percent'] < 80:
                    health['recommendations'].append("Consider preloading more data to improve cache hit rate")
            
            # Get performance metrics
            health['performance_metrics'] = self.get_performance_stats()
            
            # Determine overall status
            if health['database_connection']:
                if self._stats['errors'] == 0:
                    health['overall_status'] = 'healthy'
                elif self._stats['errors'] < self._stats['total_lookups'] * 0.1:  # Less than 10% error rate
                    health['overall_status'] = 'warning'
                else:
                    health['overall_status'] = 'unhealthy'
            else:
                health['overall_status'] = 'unhealthy'
                health['recommendations'].append("Database connection is failing - check connection parameters")
            
            # Performance recommendations
            avg_time = health['performance_metrics'].get('average_lookup_time_ms', 0)
            if avg_time > 10:
                health['recommendations'].append("Average lookup time is high - consider enabling cache or checking database performance")
            
        except Exception as e:
            health['overall_status'] = 'error'
            health['error'] = str(e)
            logger.error(f"âŒ Health check failed: {e}")
        
        return health


# Convenience functions for backward compatibility
_default_lookup_instance: Optional[SchoolDayLookup] = None


def get_default_lookup() -> SchoolDayLookup:
    """Get or create the default SchoolDayLookup instance."""
    global _default_lookup_instance
    
    if _default_lookup_instance is None:
        _default_lookup_instance = SchoolDayLookup()
    
    return _default_lookup_instance


def is_school_day(lookup_date: Optional[date] = None) -> bool:
    """
    Convenience function to check if a date is a school day.
    Uses the default lookup instance.
    
    Args:
        lookup_date: Date to check (defaults to today if None)
        
    Returns:
        True if it's a school day, False otherwise
    """
    return get_default_lookup().is_school_day(lookup_date)


# Additional convenience functions for backward compatibility
def is_weekend(lookup_date: date) -> bool:
    """Convenience function to check if a date is a weekend."""
    return get_default_lookup().is_weekend(lookup_date)


def is_public_holiday(lookup_date: date) -> bool:
    """Convenience function to check if a date is a public holiday."""
    return get_default_lookup().is_public_holiday(lookup_date)


def is_school_holiday(lookup_date: date) -> bool:
    """Convenience function to check if a date is during school holidays."""
    return get_default_lookup().is_school_holiday(lookup_date)


def is_development_day(lookup_date: date) -> bool:
    """Convenience function to check if a date is a development day."""
    return get_default_lookup().is_development_day(lookup_date)


def is_during_term(lookup_date: date) -> bool:
    """Convenience function to check if a date is during a school term."""
    return get_default_lookup().is_during_term(lookup_date)


def get_status_details(lookup_date: Optional[date] = None) -> Dict[str, Any]:
    """Convenience function to get detailed status information for a date."""
    return get_default_lookup().get_status_details(lookup_date)


# Backward-compatibility wrapper class
class SchoolDayChecker:
    """
    Backward-compatible wrapper class that provides the exact same interface
    as the original SchoolDayChecker but uses the new SchoolDayLookup system.
    
    This class can be used as a drop-in replacement for the original SchoolDayChecker.
    """
    
    def __init__(self, cache_dir: str = "~/.school_day_cache"):
        """
        Initialize the backward-compatible School Day Checker.
        
        Args:
            cache_dir: Directory for cache (maintained for compatibility but not used)
        """
        # Initialize the new lookup system
        self._lookup_system = SchoolDayLookup(preload_current_year=True)
        
        # Store cache_dir for compatibility (though not used by new system)
        self.cache_dir = Path(cache_dir).expanduser()
        
        logger.info("ðŸ”„ Initialized backward-compatible SchoolDayChecker using new SchoolDayLookup system")
    
    def is_school_day(self, lookup_date: Optional[date] = None) -> bool:
        """Backward-compatible is_school_day method."""
        return self._lookup_system.is_school_day(lookup_date)
    
    def is_weekend(self, lookup_date: date) -> bool:
        """Backward-compatible is_weekend method."""
        return self._lookup_system.is_weekend(lookup_date)
    
    def is_public_holiday(self, lookup_date: date) -> bool:
        """Backward-compatible is_public_holiday method."""
        return self._lookup_system.is_public_holiday(lookup_date)
    
    def is_school_holiday(self, lookup_date: date) -> bool:
        """Backward-compatible is_school_holiday method."""
        return self._lookup_system.is_school_holiday(lookup_date)
    
    def is_development_day(self, lookup_date: date) -> bool:
        """Backward-compatible is_development_day method."""
        return self._lookup_system.is_development_day(lookup_date)
    
    def is_during_term(self, lookup_date: date) -> bool:
        """Backward-compatible is_during_term method."""
        return self._lookup_system.is_during_term(lookup_date)
    
    def get_status_details(self, lookup_date: Optional[date] = None) -> Dict[str, Any]:
        """Backward-compatible get_status_details method."""
        return self._lookup_system.get_status_details(lookup_date)
    
    # Additional methods for enhanced functionality while maintaining compatibility
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics (enhanced functionality)."""
        return self._lookup_system.get_performance_stats()
    
    def refresh_cache(self) -> Dict[str, Any]:
        """Refresh the cache (enhanced functionality)."""
        return self._lookup_system.refresh_cache()
    
    def health_check(self) -> Dict[str, Any]:
        """Perform a health check (enhanced functionality)."""
        return self._lookup_system.health_check()


def create_school_day_checker(cache_dir: str = "~/.school_day_cache") -> SchoolDayChecker:
    """
    Factory function to create a backward-compatible SchoolDayChecker instance.
    
    Args:
        cache_dir: Cache directory (maintained for compatibility)
        
    Returns:
        SchoolDayChecker instance using the new lookup system
    """
    return SchoolDayChecker(cache_dir=cache_dir)


if __name__ == "__main__":
    # Example usage and testing
    # Only configure logging when running as main script, not when imported
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    print("ðŸš€ School Day Lookup System Test")
    print("=" * 50)
    
    try:
        # Create lookup instance
        lookup = SchoolDayLookup()
        
        # Test with today's date
        today = date.today()
        print(f"\nðŸ“… Testing with today's date: {today}")
        
        result = lookup.lookup_date(today)
        if result:
            print(f"âœ… Result: {result.is_school_day}")
            print(f"   Day of Week: {result.day_of_week}")
            print(f"   Reason: {result.reason}")
            print(f"   Term: {result.term}")
            print(f"   Lookup Time: {result.lookup_time_ms:.2f}ms")
            print(f"   Cache Hit: {result.cache_hit}")
        else:
            print("âŒ No result found")
        
        # Test performance with multiple lookups to demonstrate sub-1ms caching
        print(f"\nâš¡ Performance Test: 100 lookups to demonstrate sub-1ms caching")
        test_dates = [today + timedelta(days=i) for i in range(100)]
        
        # First pass - may hit database (cache misses)
        print("   First pass (potential cache misses):")
        start_time = datetime.now()
        
        for test_date in test_dates:
            lookup.lookup_date(test_date)
        
        first_pass_time = (datetime.now() - start_time).total_seconds() * 1000
        print(f"     Total Time: {first_pass_time:.2f}ms")
        print(f"     Average per Lookup: {first_pass_time/100:.2f}ms")
        
        # Second pass - should hit cache for sub-1ms performance
        print("   Second pass (cache hits for sub-1ms performance):")
        start_time = datetime.now()
        
        for test_date in test_dates:
            result = lookup.lookup_date(test_date)
            if result and result.cache_hit:
                continue  # This should be a cache hit
        
        second_pass_time = (datetime.now() - start_time).total_seconds() * 1000
        print(f"     Total Time: {second_pass_time:.2f}ms")
        print(f"     Average per Lookup: {second_pass_time/100:.3f}ms")
        
        if second_pass_time/100 < 1.0:
            print(f"     âœ… SUB-1MS PERFORMANCE ACHIEVED! ({second_pass_time/100:.3f}ms per lookup)")
        else:
            print(f"     âš ï¸ Performance target not met ({second_pass_time/100:.3f}ms per lookup)")
        
        # Show performance stats
        print(f"\nðŸ“Š Performance Statistics:")
        stats = lookup.get_performance_stats()
        for key, value in stats.items():
            print(f"   {key}: {value}")
        
        # Health check
        print(f"\nðŸ¥ Health Check:")
        health = lookup.health_check()
        print(f"   Overall Status: {health['overall_status']}")
        print(f"   Database Connection: {health['database_connection']}")
        print(f"   Cache Status: {health['cache_status']}")
        
        if health['recommendations']:
            print("   Recommendations:")
            for rec in health['recommendations']:
                print(f"     â€¢ {rec}")
        
        # Cache optimization analysis
        print(f"\nðŸš€ Cache Optimization Analysis:")
        optimization = lookup.optimize_cache_performance()
        print(f"   Performance Class: {optimization.get('performance_class', 'unknown')}")
        print(f"   Sub-1ms Performance: {'âœ… YES' if optimization.get('sub_1ms_performance') else 'âŒ NO'}")
        print(f"   Cache Hit Rate: {optimization.get('hit_rate_percent', 0):.1f}%")
        
        if optimization.get('actions_taken'):
            print("   Actions Taken:")
            for action in optimization['actions_taken']:
                print(f"     â€¢ {action}")
        
        if optimization.get('recommendations'):
            print("   Optimization Recommendations:")
            for rec in optimization['recommendations']:
                print(f"     â€¢ {rec}")
        
        # Test fallback mechanisms
        print(f"\nðŸ›¡ï¸ Fallback System Test:")
        fallback_test = lookup.test_fallback_strategies(today)
        print(f"   Test Date: {fallback_test['test_date']}")
        print(f"   Success Rate: {fallback_test['summary']['success_rate_percent']}% ({fallback_test['summary']['successful_strategies']}/{fallback_test['summary']['total_strategies']} strategies)")
        
        for strategy_name, result in fallback_test['strategies'].items():
            status = "âœ… SUCCESS" if result['success'] else "âŒ FAILED"
            print(f"   {strategy_name.replace('_', ' ').title()}: {status} ({result.get('test_time_ms', 0):.1f}ms)")
            if result['success'] and result.get('result'):
                school_status = "School Day" if result['result']['is_school_day'] else "Not School Day"
                print(f"     â†’ {school_status} - {result['result']['reason']}")
        
        # Display database and fallback status
        print(f"\nðŸ“Š System Status:")
        db_status = lookup.get_database_status()
        fallback_stats = lookup.get_fallback_stats()
        
        print(f"   Database Status: {db_status['current_status'].upper()}")
        print(f"   Fallback Strategy: {db_status['fallback_strategy']}")
        print(f"   Database Reliability: {fallback_stats['database_reliability_percent']:.1f}%")
        print(f"   Fallback Usage Rate: {fallback_stats['fallback_rate_percent']:.1f}%")
        
        if fallback_stats['total_fallback_calls'] > 0:
            print(f"   Total Fallback Calls: {fallback_stats['total_fallback_calls']}")
            print(f"   Last Fallback Reason: {fallback_stats['last_fallback_reason']}")
        
        print(f"\nðŸŽ¯ System Ready: {'âœ… YES' if db_status['current_status'] in ['healthy', 'degraded'] else 'âš ï¸ FALLBACK MODE'}")
        
        # Test backward compatibility
        print(f"\nðŸ”„ Backward Compatibility Test:")
        print("Testing SchoolDayChecker wrapper class...")
        
        # Create backward-compatible instance
        compat_checker = SchoolDayChecker()
        
        # Test all backward-compatible methods
        test_dates = [today, date(2025, 12, 25), date(2025, 7, 15)]  # Today, Christmas, Winter holidays
        
        for test_date in test_dates:
            print(f"\nðŸ“… Testing {test_date} ({test_date.strftime('%A')}):")
            
            # Test individual methods
            print(f"   is_school_day(): {compat_checker.is_school_day(test_date)}")
            print(f"   is_weekend(): {compat_checker.is_weekend(test_date)}")
            print(f"   is_public_holiday(): {compat_checker.is_public_holiday(test_date)}")
            print(f"   is_school_holiday(): {compat_checker.is_school_holiday(test_date)}")
            print(f"   is_development_day(): {compat_checker.is_development_day(test_date)}")
            print(f"   is_during_term(): {compat_checker.is_during_term(test_date)}")
            
            # Test detailed status (similar to original)
            status = compat_checker.get_status_details(test_date)
            print(f"   Status: {status['reason']}")
            print(f"   Data Source: {status['data_source']}")
            if status.get('term'):
                print(f"   Term: {status['term']} (Week {status.get('week_of_term', 'N/A')})")
        
        # Test default date behavior (should use today)
        print(f"\nðŸ—“ï¸ Default Date Test (today):")
        print(f"   is_school_day() with no args: {compat_checker.is_school_day()}")
        
        # Test enhanced methods
        print(f"\nâš¡ Enhanced Methods Test:")
        health = compat_checker.health_check()
        print(f"   Health Status: {health['overall_status']}")
        
        perf = compat_checker.get_performance_stats()
        print(f"   Total Lookups: {perf.get('total_lookups', 0)}")
        print(f"   Database Reliability: {perf.get('fallback_system', {}).get('database_reliability_percent', 0)}%")
        
        print(f"\nâœ… Backward Compatibility Test Complete!")
        print(f"   All original SchoolDayChecker methods are available")
        print(f"   Enhanced with database-backed performance and fallback capabilities")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
